{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b603c5bd69f12647",
      "metadata": {
        "collapsed": false,
        "id": "b603c5bd69f12647"
      },
      "source": [
        "# First test\n",
        "\n",
        "In this file, we do not apply any transformations to the data. We only rescale images and pass them through a pretrained CNN model.\n",
        "The objective is to determine whether a pretrained model is already capable of finding relevant information in these images, without transforming them, and in 224x224."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = None\n",
        "dataset2 = None"
      ],
      "metadata": {
        "id": "YpE_NxoN_1f3"
      },
      "id": "YpE_NxoN_1f3",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "1nxztB9mBk3S",
      "metadata": {
        "id": "1nxztB9mBk3S"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import toml\n",
        "import shutil\n",
        "import zipfile\n",
        "import torch\n",
        "import math\n",
        "import cv2\n",
        "from time import time\n",
        "from IPython.display import Markdown, display\n",
        "import torchvision.transforms as transforms\n",
        "from Dataset import Dataset\n",
        "from data_loading import open_preprocess_photos\n",
        "from typing import List\n",
        "#@title ## Importing libraries\n",
        "# @markdown ### ➡ Setup\n",
        "# @markdown Be sure to add all files on root"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "Azva8Bo0eSUP",
      "metadata": {
        "cellView": "form",
        "id": "Azva8Bo0eSUP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67d88824-aa7a-480c-8e3c-8a3d13453fb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "^C\n",
            "Archive:  chest-xray-pneumonia.zip\n",
            "  End-of-central-directory signature not found.  Either this file is not\n",
            "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
            "  latter case the central directory and zipfile comment will be found on\n",
            "  the last disk(s) of this archive.\n",
            "unzip:  cannot find zipfile directory in one of chest-xray-pneumonia.zip or\n",
            "        chest-xray-pneumonia.zip.zip, and cannot find chest-xray-pneumonia.zip.ZIP, period.\n"
          ]
        }
      ],
      "source": [
        "#@title ## Importing dataset folder from drive or kaggle\n",
        "choice = \"drive\"#@param [\"kaggle\", \"drive\"]\n",
        "# @markdown # kaggle\n",
        "# @markdown put kaggle.json\n",
        "if (choice == \"kaggle\"):\n",
        "  ! pip install -q kaggle\n",
        "  ! mkdir ~/.kaggle\n",
        "  kaggle = \"kaggle.json\"\n",
        "  ! cp {kaggle} ~/.kaggle/\n",
        "  ! chmod 600 ~/.kaggle/kaggle.json\n",
        "  ! kaggle datasets download -d paultimothymooney/chest-xray-pneumonia\n",
        "  ! unzip chest-xray-pneumonia.zip -d data/\n",
        "\n",
        "# @markdown # google drive (if choice is google drive)\n",
        "if (choice == \"drive\") :\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  name = 'chest-xray-pneumonia.zip' #@param {type:\"string\"}\n",
        "  ! cp /content/drive/MyDrive/{name} .\n",
        "  ! unzip chest-xray-pneumonia.zip -d data/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "kNblJCDcfoph",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNblJCDcfoph",
        "outputId": "d6d32764-af24-4eeb-e487-f4be5249e5c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n",
            "100%|██████████| 83.3M/83.3M [00:00<00:00, 130MB/s]\n"
          ]
        }
      ],
      "source": [
        "#@title ## Creating model\n",
        "# @markdown ### Restnet34 model\n",
        "\n",
        "from torchvision.models import resnet34, ResNet34_Weights\n",
        "import torch\n",
        "\n",
        "pretrained = resnet34(weights=ResNet34_Weights.IMAGENET1K_V1)\n",
        "\n",
        "pretrained.fc = torch.nn.Identity()\n",
        "pretrained.avgpool = torch.nn.Identity()\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self, pretrained):\n",
        "        super(Model, self).__init__()\n",
        "        self.pretrained = pretrained\n",
        "        self.linear1 = torch.nn.Linear(25088, 10000)\n",
        "        self.linear2 = torch.nn.Linear(10000, 1)\n",
        "        self.sigmoid = torch.nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pretrained(x)\n",
        "        x = self.linear1(x)\n",
        "        x = self.linear2(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "model = Model(pretrained)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "K7LOUOVNjkuz",
      "metadata": {
        "cellView": "form",
        "id": "K7LOUOVNjkuz"
      },
      "outputs": [],
      "source": [
        "#@title ## Load Data train\n",
        "normal_dir: str = r'./data/chest_xray/train/NORMAL'\n",
        "pneumo_dir: str = r'./data/chest_xray/train/PNEUMONIA'\n",
        "\n",
        "assert os.path.exists(normal_dir) and os.path.isdir(normal_dir), \"Normal dir isn't found or isn't a directory\"\n",
        "assert os.path.exists(pneumo_dir) and os.path.isdir(pneumo_dir), \"Pneumonia dir isn't found or isn't a directory\"\n",
        "\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    normalize,\n",
        "])\n",
        "\n",
        "\n",
        "normal = open_preprocess_photos(normal_dir, transform, (224, 224))\n",
        "pneumonia = open_preprocess_photos(pneumo_dir, transform, (224, 224))\n",
        "\n",
        "dataset = Dataset(normal, pneumonia, 0, 1, 128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbRtMkn3lOxX",
      "metadata": {
        "cellView": "form",
        "id": "bbRtMkn3lOxX"
      },
      "outputs": [],
      "source": [
        "#@title ## Load Data test\n",
        "normal_dir_test: str = r'./data/chest_xray/test/NORMAL'\n",
        "pneumo_dir_test: str = r'./data/chest_xray/test/PNEUMONIA'\n",
        "\n",
        "assert os.path.exists(normal_dir_test) and os.path.isdir(normal_dir_test), \"Normal dir isn't found or isn't a directory\"\n",
        "assert os.path.exists(pneumo_dir_test) and os.path.isdir(pneumo_dir_test), \"Pneumonia dir isn't found or isn't a directory\"\n",
        "\n",
        "normal_test = open_preprocess_photos(normal_dir_test, transform, (224, 224))\n",
        "pneumonia_test = open_preprocess_photos(pneumo_dir_test, transform, (224, 224))\n",
        "\n",
        "dataset2 = Dataset(normal_test, pneumonia_test, 0, 1, 128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "clZljZfWoNv_",
      "metadata": {
        "id": "clZljZfWoNv_"
      },
      "outputs": [],
      "source": [
        "#@title ## Training preparation\n",
        "\n",
        "def calc_acc(y_true: torch.Tensor, y_pred: torch.Tensor, threshold: float) -> float:\n",
        "  assert y_true.shape == y_pred.shape, \"Accuracy calculation received two different sized tensors\"\n",
        "  y_pred_mean = []\n",
        "\n",
        "  for pred in y_pred:\n",
        "    if pred < threshold:\n",
        "      y_pred_mean.append(0)\n",
        "    else:\n",
        "      y_pred_mean.append(1)\n",
        "\n",
        "  nb_correct = 0\n",
        "\n",
        "  for i in range(len(y_pred_mean)):\n",
        "    if y_pred_mean[i] == y_true[i]:\n",
        "      nb_correct += 1\n",
        "\n",
        "  return nb_correct / len(y_pred_mean)\n",
        "\n",
        "def train(model, optim, criterion, epochs, dataset, verbose: bool = True) -> List[list]:\n",
        "  # initialize indicator lists for later use\n",
        "  losses = []\n",
        "  mean_accs = []\n",
        "  len_dataset = len(dataset)\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    # init indicators\n",
        "    epoch_loss = 0\n",
        "    sum_acc = 0\n",
        "\n",
        "    for inputs, labels in dataset:\n",
        "      # load data and move to GPU\n",
        "      inputs = inputs.clone().to(device)\n",
        "      labels = labels.clone().to(device).unsqueeze(-1)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      outputs = model(inputs)\n",
        "\n",
        "      loss = criterion(outputs, labels)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      # calculate indicators\n",
        "      epoch_loss += loss.item()\n",
        "      sum_acc += calc_acc(labels, outputs, 0.5)\n",
        "\n",
        "      # delete temporary data that was moved to the GPU\n",
        "      del(inputs)\n",
        "      del(labels)\n",
        "\n",
        "    # shuffle dataset\n",
        "    dataset.shuffle(epoch)\n",
        "\n",
        "    # append indicators to indicator lists\n",
        "    epoch_mean_acc = sum_acc / len_dataset\n",
        "    losses.append(epoch_loss)\n",
        "    mean_accs.append(epoch_mean_acc)\n",
        "\n",
        "    # print data\n",
        "    if verbose:\n",
        "      print(f\"Epoch nb°{epoch + 1}:\")\n",
        "      print(\"Loss (sum over epoch):\\t\\t%.4f\" % epoch_loss)\n",
        "      print(\"Accuracy (mean over epoch):\\t%.4f\" % (epoch_mean_acc * 100), end=\"%\\n\\n\")\n",
        "  return [losses, mean_accs]\n",
        "\n",
        "lr=0.02 #@param {type:\"number\"}\n",
        "momentum=0.9 #@param {type:\"number\"}\n",
        "batch_size=1024 #@param {type:\"number\"}\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr, momentum)\n",
        "criterion = torch.nn.BCELoss()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## Training\n",
        "epoch = 5 #@param {type:\"integer\"}\n",
        "verbose = True #@param {type:\"boolean\"}\n",
        "\n",
        "train(model, optimizer, criterion, epoch, dataset, verbose)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "jVMOPQmX-SlK",
        "outputId": "8d39e92b-b198-4389-81f4-9b3cb593b0f9"
      },
      "id": "jVMOPQmX-SlK",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "object of type 'NoneType' has no len()",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-fded3f1a739c>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;31m#@param {type:\"boolean\"}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-431be2eaa629>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optim, criterion, epochs, dataset, verbose)\u001b[0m\n\u001b[1;32m     23\u001b[0m   \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m   \u001b[0mmean_accs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m   \u001b[0mlen_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LPViCflAocI8",
      "metadata": {
        "id": "LPViCflAocI8"
      },
      "outputs": [],
      "source": [
        "#@title ## Evaluate\n",
        "def evaluate(model: Model, dataset):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataset:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            predicted = torch.round(outputs)\n",
        "\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels.unsqueeze(-1)).sum().item()\n",
        "\n",
        "            loss += criterion(outputs, labels.unsqueeze(-1)).item()\n",
        "\n",
        "    accuracy = correct / total\n",
        "    average_loss = loss / total\n",
        "\n",
        "    print(\"Test Accuracy: {:.2f}%\".format(accuracy * 100))\n",
        "    print(\"Average Loss: {:.4f}\".format(average_loss))\n",
        "    model.train()\n",
        "\n",
        "dataset_input = \"train\" #@param [\"train\", \"test\"]\n",
        "evaluate_dataset = None\n",
        "if dataset_input == \"train\":\n",
        "  evaluate_dataset = dataset\n",
        "else:\n",
        "  evaluate_dataset = dataset2\n",
        "evaluate(model, evaluate_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JyKNq_3RT6Lc",
      "metadata": {
        "cellView": "form",
        "id": "JyKNq_3RT6Lc"
      },
      "outputs": [],
      "source": [
        "#@title ## Save model\n",
        "model_name = \"checkpoint.pth\" #@param {type:\"string\"}\n",
        "torch.save(model.state_dict(), model_name)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}