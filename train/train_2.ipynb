{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b603c5bd69f12647",
      "metadata": {
        "collapsed": false,
        "id": "b603c5bd69f12647"
      },
      "source": [
        "# First test\n",
        "\n",
        "In this file, we do not apply any transformations to the data. We only rescale images and pass them through a pretrained CNN model.\n",
        "The objective is to determine whether a pretrained model is already capable of finding relevant information in these images, without transforming them, and in 224x224."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1nxztB9mBk3S",
      "metadata": {
        "cellView": "form",
        "id": "1nxztB9mBk3S"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import toml\n",
        "import shutil\n",
        "import zipfile\n",
        "import torch\n",
        "import math\n",
        "import cv2\n",
        "from time import time\n",
        "from IPython.display import Markdown, display\n",
        "import torchvision.transforms as transforms\n",
        "from Dataset import Dataset\n",
        "from data_loading import open_preprocess_photos\n",
        "#@title ## Importing library, functions\n",
        "# @markdown ### ➡ Setup\n",
        "# @markdown Be sure to add all files on root"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Azva8Bo0eSUP",
      "metadata": {
        "cellView": "form",
        "id": "Azva8Bo0eSUP"
      },
      "outputs": [],
      "source": [
        "#@title ## Importing dataset folder from drive or kaggle\n",
        "choice = \"kaggle\"#@param [\"kaggle\", \"drive\"]\n",
        "# @markdown # kaggle\n",
        "# @markdown put kaggle.json\n",
        "if (choice == \"kaggle\"):\n",
        "  ! pip install -q kaggle\n",
        "  ! mkdir ~/.kaggle\n",
        "  kaggle = \"kaggle.json\"\n",
        "  ! cp {kaggle} ~/.kaggle/\n",
        "  ! chmod 600 ~/.kaggle/kaggle.json\n",
        "  ! kaggle datasets download -d paultimothymooney/chest-xray-pneumonia\n",
        "  ! unzip chest-xray-pneumonia.zip -d data/\n",
        "\n",
        "# @markdown # google drive (if choice is google drive)\n",
        "if (choice == \"drive\") :\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  name = 'chest-xray-pneumonia.zip' #@param {type:\"string\"}\n",
        "  ! cp /content/drive/MyDrive/{name} .\n",
        "  ! unzip chest-xray-pneumonia.zip -d data/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kNblJCDcfoph",
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNblJCDcfoph",
        "outputId": "d127a586-fb73-4a2e-c95d-dac3eb299917"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n",
            "100%|██████████| 83.3M/83.3M [00:01<00:00, 50.1MB/s]\n"
          ]
        }
      ],
      "source": [
        "#@title ## Creating model\n",
        "# @markdown ### Restnet34 model\n",
        "\n",
        "from torchvision.models import resnet34, ResNet34_Weights\n",
        "import torch\n",
        "\n",
        "pretrained = resnet34(weights=ResNet34_Weights.IMAGENET1K_V1)\n",
        "\n",
        "pretrained.fc = torch.nn.Identity()\n",
        "pretrained.avgpool = torch.nn.Identity()\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self, pretrained):\n",
        "        super(Model, self).__init__()\n",
        "        self.pretrained = pretrained\n",
        "        self.linear1 = torch.nn.Linear(25088, 10000)\n",
        "        self.linear2 = torch.nn.Linear(10000, 1)\n",
        "        self.sigmoid = torch.nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pretrained(x)\n",
        "        x = self.linear1(x)\n",
        "        x = self.linear2(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "model = Model(pretrained)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "K7LOUOVNjkuz",
      "metadata": {
        "cellView": "form",
        "id": "K7LOUOVNjkuz"
      },
      "outputs": [],
      "source": [
        "#@title ## Load Data train\n",
        "normal_dir: str = r'./data/chest_xray/train/NORMAL'\n",
        "pneumo_dir: str = r'./data/chest_xray/train/PNEUMONIA'\n",
        "\n",
        "assert os.path.exists(normal_dir) and os.path.isdir(normal_dir), \"Normal dir isn't found or isn't a directory\"\n",
        "assert os.path.exists(pneumo_dir) and os.path.isdir(pneumo_dir), \"Pneumonia dir isn't found or isn't a directory\"\n",
        "\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    normalize,\n",
        "])\n",
        "\n",
        "\n",
        "normal = open_preprocess_photos(normal_dir, transform, (224, 224))\n",
        "pneumonia = open_preprocess_photos(pneumo_dir, transform, (224, 224))\n",
        "\n",
        "dataset = Dataset(normal, pneumonia, 0, 1, 128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbRtMkn3lOxX",
      "metadata": {
        "cellView": "form",
        "id": "bbRtMkn3lOxX"
      },
      "outputs": [],
      "source": [
        "#@title ## Load Data test\n",
        "normal_dir_test: str = r'./data/chest_xray/test/NORMAL'\n",
        "pneumo_dir_test: str = r'./data/chest_xray/test/PNEUMONIA'\n",
        "\n",
        "assert os.path.exists(normal_dir_test) and os.path.isdir(normal_dir_test), \"Normal dir isn't found or isn't a directory\"\n",
        "assert os.path.exists(pneumo_dir_test) and os.path.isdir(pneumo_dir_test), \"Pneumonia dir isn't found or isn't a directory\"\n",
        "\n",
        "normal_test = open_preprocess_photos(normal_dir_test, transform, (224, 224))\n",
        "pneumonia_test = open_preprocess_photos(pneumo_dir_test, transform, (224, 224))\n",
        "\n",
        "dataset2 = Dataset(normal_test, pneumonia_test, 0, 1, 128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "clZljZfWoNv_",
      "metadata": {
        "cellView": "form",
        "id": "clZljZfWoNv_"
      },
      "outputs": [],
      "source": [
        "#@title ## Training preparation\n",
        "def train_one_epoch(model, criterion, optimizer, dataloader):\n",
        "  epoch_index = 0\n",
        "  running_loss = 0.\n",
        "  last_loss = 0.\n",
        "\n",
        "  # Here, we use enumerate(training_loader) instead of\n",
        "  # iter(training_loader) so that we can track the batch\n",
        "  # index and do some intra-epoch reporting\n",
        "  i = 0\n",
        "  for inputs, labels in dataset:\n",
        "    i += 1\n",
        "    # Every data instance is an input + label pair\n",
        "    inputs = inputs.clone().to(device)\n",
        "    labels = labels.clone().to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, labels.unsqueeze(-1))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    del(inputs)\n",
        "    del(labels)\n",
        "\n",
        "    running_loss += loss.item()\n",
        "    last_loss = running_loss / 1000 # loss per batch\n",
        "    tb_x = epoch_index * len(dataset) + i + 1\n",
        "    running_loss = 0.\n",
        "  return last_loss\n",
        "\n",
        "lr=0.02 #@param {type:\"number\"}\n",
        "momentum=0.9 #@param {type:\"number\"}\n",
        "batch_size=1024 #@param {type:\"number\"}\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr, momentum)\n",
        "criterion = torch.nn.BCELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LPViCflAocI8",
      "metadata": {
        "cellView": "form",
        "id": "LPViCflAocI8"
      },
      "outputs": [],
      "source": [
        "#@title ## Evaluate\n",
        "def evaluate(model: Model, dataset):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataset:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            predicted = torch.round(outputs)\n",
        "\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels.unsqueeze(-1)).sum().item()\n",
        "\n",
        "            loss += criterion(outputs, labels.unsqueeze(-1)).item()\n",
        "\n",
        "    accuracy = correct / total\n",
        "    average_loss = loss / total\n",
        "\n",
        "    print(\"Test Accuracy: {:.2f}%\".format(accuracy * 100))\n",
        "    print(\"Average Loss: {:.4f}\".format(average_loss))\n",
        "    model.train\n",
        "\n",
        "evaluate(model, dataset_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JyKNq_3RT6Lc",
      "metadata": {
        "cellView": "form",
        "id": "JyKNq_3RT6Lc"
      },
      "outputs": [],
      "source": [
        "#@title ## Save model\n",
        "model_name = \"checkpoint.pth\" #@param {type:\"string\"}\n",
        "torch.save(model.state_dict(), model_name)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
