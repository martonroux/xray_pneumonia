{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "from torchvision import transforms\n",
    "from Dataset import Dataset\n",
    "from data_loading import open_preprocess_photos, open_preprocess_photos_flip\n",
    "from typing import List"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-16T21:25:42.004158Z",
     "start_time": "2024-05-16T21:25:39.868715Z"
    }
   },
   "id": "196cc13c121a22af",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6aa5643d1bc2a4fa"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-16T21:25:46.789925Z",
     "start_time": "2024-05-16T21:25:46.486944Z"
    }
   },
   "source": [
    "from torchvision.models import resnet34, ResNet34_Weights\n",
    "import torch\n",
    "\n",
    "pretrained = resnet34(weights=ResNet34_Weights.IMAGENET1K_V1)\n",
    "\n",
    "pretrained.fc = torch.nn.Identity()\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, pretrained):\n",
    "        super(Model, self).__init__()\n",
    "        self.pretrained = pretrained\n",
    "        self.linear1 = torch.nn.Linear(512, 256)\n",
    "        self.linear2 = torch.nn.Linear(256, 1)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pretrained(x)\n",
    "        x = self.linear1(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "model = Model(pretrained)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "model.load_state_dict(torch.load('../model.pt'))  # loading previously trained model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-16T21:25:47.845886Z",
     "start_time": "2024-05-16T21:25:47.767727Z"
    }
   },
   "id": "5b54691463830c61",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "70686cd45eae1f7f"
  },
  {
   "cell_type": "code",
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-16T21:26:12.731020Z",
     "start_time": "2024-05-16T21:26:12.728858Z"
    }
   },
   "id": "7c525bb309aeb461",
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": [
    "normal_dir: str = r'../chest_xray/train/NORMAL'\n",
    "pneumo_dir: str = r'../chest_xray/train/PNEUMONIA'\n",
    "\n",
    "assert os.path.exists(normal_dir) and os.path.isdir(normal_dir), \"Normal dir isn't found or isn't a directory\"\n",
    "assert os.path.exists(pneumo_dir) and os.path.isdir(pneumo_dir), \"Pneumonia dir isn't found or isn't a directory\"\n",
    "\n",
    "normal = open_preprocess_photos_flip(normal_dir, transform, (224, 224))\n",
    "pneumonia = open_preprocess_photos(pneumo_dir, transform, (224, 224))\n",
    "\n",
    "dataset_train = Dataset(normal, pneumonia[:len(normal)], 0, 1, 64)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-16T21:27:14.106451Z",
     "start_time": "2024-05-16T21:26:37.565167Z"
    }
   },
   "id": "9d48b9745b43fb88",
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": [
    "normal_dir_test: str = r'../chest_xray/test/NORMAL'\n",
    "pneumo_dir_test: str = r'../chest_xray/test/PNEUMONIA'\n",
    "\n",
    "assert os.path.exists(normal_dir_test) and os.path.isdir(normal_dir_test), \"Normal dir isn't found or isn't a directory\"\n",
    "assert os.path.exists(pneumo_dir_test) and os.path.isdir(pneumo_dir_test), \"Pneumonia dir isn't found or isn't a directory\"\n",
    "\n",
    "normal_test = open_preprocess_photos_flip(normal_dir_test, transform, (224, 224))\n",
    "pneumonia_test = open_preprocess_photos(pneumo_dir_test, transform, (224, 224))\n",
    "\n",
    "dataset_test = Dataset(normal_test, pneumonia_test[:len(normal_test)], 0, 1, 64)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-16T21:27:18.267444Z",
     "start_time": "2024-05-16T21:27:14.107445Z"
    }
   },
   "id": "6ec16eb382f612f5",
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": [
    "def calc_acc(y_true: torch.Tensor, y_pred: torch.Tensor, threshold: float) -> float:\n",
    "  assert y_true.shape == y_pred.shape, \"Accuracy calculation received two different sized tensors\"\n",
    "  y_pred_mean = []\n",
    "\n",
    "  for pred in y_pred:\n",
    "    if pred < threshold:\n",
    "      y_pred_mean.append(0)\n",
    "    else:\n",
    "      y_pred_mean.append(1)\n",
    "\n",
    "  nb_correct = 0\n",
    "\n",
    "  for i in range(len(y_pred_mean)):\n",
    "    if y_pred_mean[i] == y_true[i]:\n",
    "      nb_correct += 1\n",
    "\n",
    "  return nb_correct / len(y_pred_mean)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-16T21:28:05.349902Z",
     "start_time": "2024-05-16T21:28:05.347671Z"
    }
   },
   "id": "b5e21c03013bce43",
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "def evaluate(model: Model, dataset: Dataset, criterion) -> tuple:\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataset:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            predicted = torch.round(outputs)\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels.unsqueeze(-1)).sum().item()\n",
    "\n",
    "            loss += criterion(outputs, labels.unsqueeze(-1)).item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    average_loss = loss / total\n",
    "    model.train()\n",
    "    \n",
    "    return accuracy, average_loss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-16T21:28:07.208268Z",
     "start_time": "2024-05-16T21:28:07.204838Z"
    }
   },
   "id": "d532061f8b7cb7e5",
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": [
    "def train(model, optim, criterion, epochs, dataset, verbose: bool = True) -> List[list]:\n",
    "    # initialize indicator lists for later use\n",
    "    losses = []\n",
    "    mean_accs = []\n",
    "    len_dataset = len(dataset)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # init indicators\n",
    "        epoch_loss = 0\n",
    "        sum_acc = 0\n",
    "        \n",
    "        for inputs, labels in dataset:\n",
    "            # load data and move to GPU\n",
    "            inputs = inputs.clone().to(device)\n",
    "            labels = labels.clone().to(device).unsqueeze(-1)\n",
    "            \n",
    "            optim.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            \n",
    "            # calculate indicators\n",
    "            epoch_loss += loss.item()\n",
    "            sum_acc += calc_acc(labels, outputs, 0.5)\n",
    "            \n",
    "            del inputs, labels\n",
    "        \n",
    "        # shuffle dataset\n",
    "        dataset.shuffle(epoch)\n",
    "        \n",
    "        # append indicators to indicator lists\n",
    "        epoch_mean_acc = sum_acc / len_dataset\n",
    "        losses.append(epoch_loss)\n",
    "        mean_accs.append(epoch_mean_acc)\n",
    "        \n",
    "        #test_acc, test_loss = evaluate(model, test)\n",
    "        test_acc, test_loss = 0, 0\n",
    "        \n",
    "        # print data\n",
    "        if verbose:\n",
    "            print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_mean_acc:.4f}, Test Accuracy: {test_acc:.4f}, Test Loss: {test_loss:.4f}\")\n",
    "    return [losses, mean_accs]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-16T21:28:08.429465Z",
     "start_time": "2024-05-16T21:28:08.426445Z"
    }
   },
   "id": "307678155fe53c48",
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": [
    "lr=1e-3\n",
    "momentum=0.9\n",
    "batch_size=256\n",
    "epoch=5\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr, momentum)\n",
    "criterion = torch.nn.BCELoss()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-16T21:28:15.332050Z",
     "start_time": "2024-05-16T21:28:15.329167Z"
    }
   },
   "id": "268d1f5e9c8199c8",
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m dataset_train\u001B[38;5;241m.\u001B[39mchange_batch_size(batch_size, \u001B[38;5;241m0\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'dataset_train' is not defined"
     ]
    }
   ],
   "source": [
    "dataset_train.change_batch_size(batch_size, 0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T17:34:33.138388Z",
     "start_time": "2024-03-21T17:34:33.129050Z"
    }
   },
   "id": "d65ba01a857d10df",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.8548, Accuracy: 0.9849, Test Accuracy: 0.0000, Test Loss: 0.0000\n",
      "Epoch [2/5], Loss: 0.3255, Accuracy: 0.9948, Test Accuracy: 0.0000, Test Loss: 0.0000\n",
      "Epoch [3/5], Loss: 0.1262, Accuracy: 0.9991, Test Accuracy: 0.0000, Test Loss: 0.0000\n",
      "Epoch [4/5], Loss: 0.1036, Accuracy: 0.9993, Test Accuracy: 0.0000, Test Loss: 0.0000\n",
      "Epoch [5/5], Loss: 0.0446, Accuracy: 0.9998, Test Accuracy: 0.0000, Test Loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "losses, accs = train(model, optimizer, criterion, epoch, dataset_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T16:50:52.174787Z",
     "start_time": "2024-03-21T16:49:43.206037Z"
    }
   },
   "id": "b220d00e9bdcaaf8",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "source": [
    "evaluate(model, dataset_test, criterion)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-16T21:28:18.113371Z",
     "start_time": "2024-05-16T21:28:17.240392Z"
    }
   },
   "id": "97296d5f378b41b7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7925407925407926, 0.010263340143890647)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f6dc143a8213ec92",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
