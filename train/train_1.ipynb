{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# First test\n",
        "\n",
        "In this file, we do not apply any transformations to the data. We only rescale images and pass them through a pretrained CNN model.\n",
        "The objective is to determine whether a pretrained model is already capable of finding relevant information in these images, without transforming them, and in 224x224."
      ],
      "metadata": {
        "collapsed": false,
        "id": "b603c5bd69f12647"
      },
      "id": "b603c5bd69f12647"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Dataset from Kaggle"
      ],
      "metadata": {
        "id": "dy_KZ82pbrwJ"
      },
      "id": "dy_KZ82pbrwJ"
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -q kaggle"
      ],
      "metadata": {
        "id": "vrSGarVrZyNQ"
      },
      "id": "vrSGarVrZyNQ",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files"
      ],
      "metadata": {
        "id": "BairTiGVZ0Sx"
      },
      "id": "BairTiGVZ0Sx",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.upload()"
      ],
      "metadata": {
        "id": "cG5pUPSlZ4wJ"
      },
      "id": "cG5pUPSlZ4wJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "BeASqa7BaHh9"
      },
      "id": "BeASqa7BaHh9",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "7X_0tCTvaJuX"
      },
      "id": "7X_0tCTvaJuX",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "ZDd_MCbvaZk6"
      },
      "id": "ZDd_MCbvaZk6",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle datasets download -d paultimothymooney/chest-xray-pneumonia"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IaTimo2YarUy",
        "outputId": "659288c0-c33b-4c6d-aa09-e7ce1b4ccb03"
      },
      "id": "IaTimo2YarUy",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading chest-xray-pneumonia.zip to /content\n",
            "100% 2.29G/2.29G [00:21<00:00, 155MB/s]\n",
            "100% 2.29G/2.29G [00:21<00:00, 117MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip chest-xray-pneumonia.zip -d data/"
      ],
      "metadata": {
        "id": "m3Ou5AWBbAQX"
      },
      "id": "m3Ou5AWBbAQX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load model"
      ],
      "metadata": {
        "id": "JPydo_twbu-C"
      },
      "id": "JPydo_twbu-C"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "initial_id",
      "metadata": {
        "collapsed": true,
        "ExecuteTime": {
          "end_time": "2024-02-22T14:55:38.201949Z",
          "start_time": "2024-02-22T14:55:38.198214Z"
        },
        "id": "initial_id"
      },
      "outputs": [],
      "source": [
        "from torchvision.models import resnet50, ResNet50_Weights\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n",
            "100%|██████████| 97.8M/97.8M [00:01<00:00, 71.7MB/s]\n"
          ]
        }
      ],
      "source": [
        "pretrained = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-22T14:56:31.555413Z",
          "start_time": "2024-02-22T14:55:59.871139Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9e49866fec32f447",
        "outputId": "4791b829-6f9a-424d-ae82-11727a880ad9"
      },
      "id": "9e49866fec32f447",
      "execution_count": 12
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "pretrained.fc = torch.nn.Identity()\n",
        "pretrained.avgpool = torch.nn.Identity()"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-22T14:56:49.868832Z",
          "start_time": "2024-02-22T14:56:49.865367Z"
        },
        "id": "3986ae0d99e82749"
      },
      "id": "3986ae0d99e82749",
      "execution_count": 13
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "class Model(torch.nn.Module):\n",
        "    def __init__(self, pretrained):\n",
        "        super(Model, self).__init__()\n",
        "        self.pretrained = pretrained\n",
        "        self.linear1 = torch.nn.Linear(224*224*2, 10000)\n",
        "        self.linear2 = torch.nn.Linear(10000, 1)\n",
        "        self.sigmoid = torch.nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pretrained(x)\n",
        "        for (i, batch) in enumerate(x):\n",
        "          xtemp = self.linear1(batch)\n",
        "          xtemp = self.linear2(xtemp)\n",
        "          xtemp = self.sigmoid(xtemp)\n",
        "          x[i] = xtemp\n",
        "        return x"
      ],
      "metadata": {
        "id": "bc1172f3102d9723"
      },
      "id": "bc1172f3102d9723",
      "execution_count": 14
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "model = Model(pretrained)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-22T14:59:37.081173Z",
          "start_time": "2024-02-22T14:59:37.076418Z"
        },
        "id": "f9b07e53f2ab77b2"
      },
      "id": "f9b07e53f2ab77b2",
      "execution_count": 15
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "b67892757aa2e826"
      },
      "id": "b67892757aa2e826",
      "execution_count": 16
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "Pset2Yj0cUwW"
      },
      "id": "Pset2Yj0cUwW",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Data and Preprocess\n",
        "\n",
        "\n",
        "In this test, the only preprocessing applied is a basic resize to (224, 224, 3), and a normalization using Pytorch Transforms.  \n",
        "We do not modify the images. Aspect ratio is taken into account during the resize process."
      ],
      "metadata": {
        "id": "7nI5uNGwdCW3"
      },
      "id": "7nI5uNGwdCW3"
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import os\n",
        "import cv2\n",
        "import torchvision.transforms as transforms\n",
        "from Dataset import Dataset\n",
        "from data_loading import open_preprocess_photos"
      ],
      "metadata": {
        "id": "zxHmIKR2ctjW"
      },
      "id": "zxHmIKR2ctjW",
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normal_dir: str = r'./data/chest_xray/test/NORMAL'\n",
        "pneumo_dir: str = r'./data/chest_xray/test/PNEUMONIA'\n",
        "\n",
        "assert os.path.exists(normal_dir) and os.path.isdir(normal_dir), \"Normal dir isn't found or isn't a directory\"\n",
        "assert os.path.exists(pneumo_dir) and os.path.isdir(pneumo_dir), \"Pneumonia dir isn't found or isn't a directory\""
      ],
      "metadata": {
        "id": "eQIBIj9DdOzf"
      },
      "id": "eQIBIj9DdOzf",
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    normalize,\n",
        "])"
      ],
      "metadata": {
        "id": "kQGm2Ghv-V_N"
      },
      "id": "kQGm2Ghv-V_N",
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normal = open_preprocess_photos(normal_dir, transform, (224, 224))\n",
        "pneumonia = open_preprocess_photos(pneumo_dir, transform, (224, 224))"
      ],
      "metadata": {
        "id": "IPn65rOq-Oao"
      },
      "id": "IPn65rOq-Oao",
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = Dataset(normal, pneumonia, 0, 1, 128)"
      ],
      "metadata": {
        "id": "k-HjkrLq-3XQ"
      },
      "id": "k-HjkrLq-3XQ",
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset[0][0])  # Should be as big as the given batch_size, so 128"
      ],
      "metadata": {
        "id": "wxCXfEka-8Kq",
        "outputId": "ff838bd5-af39-4219-92ef-f7304ff6c0a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "wxCXfEka-8Kq",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "128"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "RQQHnlHifMic"
      },
      "id": "RQQHnlHifMic"
    },
    {
      "cell_type": "code",
      "source": [
        "model.forward(dataset[0].to(device).unsqueeze(0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfYwsthLe_Hn",
        "outputId": "b4c441f0-73a9-4ee8-eb59-3e75db283d07"
      },
      "id": "NfYwsthLe_Hn",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4623, 0.4623, 0.4623,  ..., 0.4623, 0.4623, 0.4623]],\n",
              "       device='cuda:0', grad_fn=<AsStridedBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr=1e-2\n",
        "momentum=0.9\n",
        "batch_size=1024\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr, momentum)\n",
        "criterion = torch.nn.BCELoss()              # Check for data imbalance if weight is needed"
      ],
      "metadata": {
        "id": "53zGwbrnhgiZ"
      },
      "id": "53zGwbrnhgiZ",
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YkRTWi59uQMP",
        "outputId": "22b1ce4b-9ca0-4b34-d585-e67a99520a77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "YkRTWi59uQMP",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xK4CXjkAkRMN"
      },
      "id": "xK4CXjkAkRMN",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}